{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\FakeNews\\\\results.csv\")\n",
    "test_data=pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\FakeNews\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking For Empty values in the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of empty rows:{}\".format(test_data.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of empty rows in results:{}\".format(results.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.fillna('NA',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_filter=(test_data['title']=='NA')\n",
    "nan_title_data=test_data.loc[nan_filter]\n",
    "nan_title_ids=nan_title_data['id']\n",
    "print(len(nan_title_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.set_index('id',inplace=True)\n",
    "results.set_index('id',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.drop(index=nan_title_ids,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(index=nan_title_ids,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading model file and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models \n",
    "news_predictor=models.load_model('news_predictor.h5') ## Loading Back the model file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pkl','rb') as f:\n",
    "    \n",
    "    tokens=pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=test_data['title']\n",
    "X_id=test_data.index.values.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(test_input):\n",
    "    \n",
    "    news_data=re.sub('[^a-zA-Z]',' ',test_input)\n",
    "    news_data=news_data.lower()\n",
    "    news_data=news_data.split()\n",
    "    ps=PorterStemmer()\n",
    "    news_data=[ps.stem(word) for word in news_data if word not in set(stopwords.words('english'))]\n",
    "    news_data=' '.join(news_data)\n",
    "    \n",
    "    return news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " tokens.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tokens(processed_news_data):\n",
    "    \n",
    "    vocab_size=15000\n",
    "    \n",
    "    processed_news_data=[processed_news_data]\n",
    "    token_news_data=tokens.texts_to_sequences(processed_news_data)\n",
    "        \n",
    "    return token_news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_padding(encoded_news_data):\n",
    "    \n",
    "    sentence_length=47\n",
    "    padded_news_data=pad_sequences(encoded_news_data,padding=\"post\",maxlen=sentence_length)\n",
    "    return padded_news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('news_results.csv','a',newline='') as f:\n",
    "        \n",
    "    csv_writer=csv.writer(f)\n",
    "    csv_writer.writerow(['ID','Prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=list(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(X_test)):\n",
    "    \n",
    "    test_input=X_test[i]\n",
    "    input_id=X_id[i]\n",
    "    processed_input=preprocess_text(test_input)\n",
    "    token_input=add_tokens(processed_input)\n",
    "    padded_news_input=add_padding(token_input)\n",
    "    news_input=np.array(padded_news_input)\n",
    "    news_result=news_predictor.predict(news_input)\n",
    "    if news_result>0.5:\n",
    "        \n",
    "        result_value=1\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        result_value=0\n",
    "    with open('news_results.csv','a',newline='') as f:\n",
    "        \n",
    "       csv_writer=csv.writer(f)\n",
    "       csv_writer.writerow([input_id,result_value])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=pd.read_csv('news_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vals=prediction['Prediction']\n",
    "predicted_vals=np.array(predicted_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_vals=results['label']\n",
    "actual_vals=np.array(actual_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actual_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_compare=np.concatenate((actual_vals.reshape(len(actual_vals),1),predicted_vals.reshape(len(predicted_vals),1)),1)\n",
    "values_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score\n",
    "cm=confusion_matrix(actual_vals,predicted_vals)\n",
    "print(\"Confusion Matrix: \")\n",
    "print(\" \")\n",
    "print(cm)\n",
    "print(\"\")\n",
    "acs=accuracy_score(actual_vals,predicted_vals)\n",
    "acs=round(acs,2)*100\n",
    "print(\"The accuracy score:{}%\".format(acs))\n",
    "print(\"\")\n",
    "precision=precision_score(actual_vals,predicted_vals)\n",
    "precision=round(precision,2)*100\n",
    "print(\"The precision score:{}%\".format(precision))\n",
    "print(\"\")\n",
    "recall=recall_score(actual_vals,predicted_vals)\n",
    "recall=round(recall,2)*100\n",
    "print(\"The recall score:{}%\".format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
